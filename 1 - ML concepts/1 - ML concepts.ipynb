{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning and Deep Learning\n",
    "### Core ML concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "For general machine learning references, see e.g. [Bishop](#Bishop06), [Hastie et al](#Hastie01) and [Murphy](#Murphy12). In order to motivate some of the most important concepts, let's first review the definition of machine learning itself. There are several definitions and perspectives on this, but one of the most popular is due to [Mitchell](#Mitchell97):\n",
    "\n",
    "> A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "We can unpick this definition by looking at what is meant by _experience E, tasks T_ and _performance measure P_. \n",
    "\n",
    "*Tasks T.* One of the strengths of deep learning models are their flexibility to solve a wide range of problem tasks. Typical tasks could include:\n",
    "\n",
    "* Classification\n",
    "* Regression\n",
    "* Clustering\n",
    "* Anomaly detection\n",
    "* Density estimation\n",
    "\n",
    "*Experience E.* This relates to the type of data that is used to accomplish the given task. The data could be labelled examples (such as images of digits and their corresponding labels), unlabelled examples, or streaming data coming from an environment that an agent interacts with (this is the setting for reinforcement learning). Of course, the type of data needs to be appropriate for the learning task. A typical assumption is that the data is independent and identically distributed (iid).\n",
    "\n",
    "*Performance measure P.* Given a learning task T and experience E, we then need a way of measuring how well a machine learning system accomplishes the task T. For example, for a regression task this could be the mean squared error, or for a binary classification task we could use binary cross entropy, or area under the ROC curve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dataset\n",
    "\n",
    "The following toy example works through fitting a regression model, and demonstrates several key concepts in machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a regression dataset\n",
    "\n",
    "def f(x, noise_std=0.0, n_samples=100):\n",
    "    y_true = 0.3 * x**2 + 0.5 * x - 0.5 + 3 \n",
    "    noise = noise_std * np.random.randn(n_samples, 1)\n",
    "    return y_true + noise\n",
    "\n",
    "X = np.random.uniform(low=-5, high=5, size=100)[..., np.newaxis]\n",
    "y = f(X, noise_std=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "xlinspace = np.linspace(-5, 5, 100)[..., np.newaxis]\n",
    "plt.plot(xlinspace, f(xlinspace), c='C01')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "We have a **dataset** $\\mathcal{D} := (\\mathbf{x}_i, y_i)_{i=1}^N$ consisting of $N$ examples of inputs $\\mathbf{x} \\in\\mathbb{R}^d$ and targets $y\\in\\mathbb{R}$. \n",
    "\n",
    "We will denote the $j$-th **input feature** ($j=1,\\ldots,d$) of the input $\\mathbf{x}$ by $x^{(j)}$.\n",
    "\n",
    "Our linear regression model tries to find the best parameters $\\theta_j$ ($j=0, 1,\\ldots,d$) such that\n",
    "\n",
    "$$\n",
    "f_\\theta(\\mathbf{x}) := \\theta_0 + \\sum_{j=1}^d \\theta_j x^{(j)}\n",
    "$$\n",
    "\n",
    "is a good predictor of the **target** value $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify notation, we will often augment the **feature vector** by adding a constant 1 feature to the inputs:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}} := [1, x^{(1)}, \\ldots, x^{(d)}]\n",
    "$$\n",
    "\n",
    "Then our linear regression model can be written\n",
    "\n",
    "$$\n",
    "f_\\theta(\\mathbf{x}) := \\sum_{j=0}^d \\theta_j x^{(j)} = \\theta^T \\hat{\\mathbf{x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\theta$ are found as the minimiser of the following mean squared error (MSE) **loss function**:\n",
    "\n",
    "$$\n",
    "{L}_{MSE}(\\theta) := \\frac{1}{N} \\sum_{i=1}^N (\\theta^T\\hat{\\mathbf{x}}_i - y_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "model.coef_, model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, data=None, ylim=None, plot_true=True):\n",
    "    xlinspace = np.linspace(-5, 5, 100)[..., np.newaxis]\n",
    "    predictions = model.predict(xlinspace)  # xlinspace @ model.coef_ + model.intercept_\n",
    "\n",
    "    plt.plot(xlinspace, predictions, label='model')\n",
    "    if plot_true:\n",
    "        plt.plot(xlinspace, f(xlinspace), label='true')\n",
    "    if data is not None:\n",
    "        plt.scatter(data[0], data[1], alpha=0.2)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, data=(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(model.predict(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear basis functions\n",
    "\n",
    "We can make our linear model more expressive (or increase the **capacity** of our model) with the use of nonlinear **basis functions**.\n",
    "\n",
    "So far our linear regression model just uses the **input feature** provided in our data:\n",
    "\n",
    "$$\n",
    "f_\\theta(\\mathbf{x}) := \\theta_0 + \\theta_1 x\n",
    "$$\n",
    "\n",
    "However, the feature vector in our linear regression model can be anything, so we can also consider linear regression models of the form\n",
    "\n",
    "$$\n",
    "f_\\theta(\\mathbf{x}) = \\sum_{j=1}^M \\theta_j\\phi_j(\\mathbf{x}),\n",
    "$$\n",
    "\n",
    "where the $\\phi_j$ are called the **basis functions**. These basis functions can be nonlinear in general. For example, we could consider degree $P$ polynomial regressors of the form\n",
    "\n",
    "$$\n",
    "f_\\theta(\\mathbf{x}) = \\theta_0 + \\theta_1 x + \\theta_2 x^2 + \\cdots + \\theta_P x^P = \\sum_{j=0}^P \\theta_j x^j.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit polynomial regressors for different degrees\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "P = 2\n",
    "\n",
    "poly = PolynomialFeatures(P, include_bias=False)\n",
    "poly_features = poly.fit_transform(X)\n",
    "model = LinearRegression()\n",
    "model.fit(poly_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(P), LinearRegression())\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, data=(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(model.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_degrees = 20\n",
    "degrees = np.arange(num_degrees)\n",
    "\n",
    "polynomial_regressors = []\n",
    "for degree in degrees:\n",
    "    poly_regressor = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_regressor.fit(X, y)\n",
    "    polynomial_regressors.append(poly_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = [mean_squared_error(model.predict(X), y) for model in polynomial_regressors]\n",
    "plt.semilogy(degrees, evaluations)\n",
    "plt.xticks(degrees)\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(polynomial_regressors[-1], data=(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splits\n",
    "In order to obtain a fair measure of the performance of an ML model, we typically split our available data into separate partitions. \n",
    "\n",
    "One partition will be the **training set**. This is used to infer the optimal parameters of our model, whilst the remaining data (also called **hold-out** data) is used purely for evaluation and not for training (optimising parameters). \n",
    "\n",
    "We may want to choose certain hyperparameters of our model (such as the polynomial degree $P$), in which case we can evaluate our model on the held-out data for each choice of hyperparameter and choose the hyperparameters that maximise the held-out data performance. In this case, the held-out data is called a **validation set**, and this process of choosing the best hyperparameters is **validation**. \n",
    "\n",
    "In addition, we may choose to define a third partition for a **test set**, which is used for a final evaluation of the model.\n",
    "\n",
    "You should never use the validation or test splits for directly training the model (optimising its parameters).\n",
    "\n",
    "In the following cell we use `sklearn` to make a training and validation partition of our toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the train_test_split from sklearn to conveniently split the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"x shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.4)\n",
    "print(\"\\nx_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"\\nx_val shape:\", x_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that in practice what we optimise during training is the loss\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "L_{MSE}(\\theta) = \\frac{1}{| \\mathcal{D}_{train} |}\\sum_{x_i, y_i\\in \\mathcal{D}_{train}}(f_\\theta(\\mathbf{x}_i) - y_i)^2, \\tag{2}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{D}_{train}$ denotes the training data partition.\n",
    "\n",
    "The following cells illustrate this for our toy dataset, by creating an example regression function and computing the training loss using the inbuilt function from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_degrees = 20\n",
    "degrees = np.arange(num_degrees)\n",
    "\n",
    "polynomial_regressors = []\n",
    "for degree in degrees:\n",
    "    poly_regressor = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    poly_regressor.fit(x_train, y_train)\n",
    "    polynomial_regressors.append(poly_regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = [mean_squared_error(model.predict(x_train), y_train) for model in polynomial_regressors]\n",
    "val_loss = [mean_squared_error(model.predict(x_val), y_val) for model in polynomial_regressors]\n",
    "plt.semilogy(degrees, train_loss, label='Train MSE')\n",
    "plt.semilogy(degrees, val_loss, label='Val MSE')\n",
    "plt.xticks(degrees)\n",
    "plt.xlabel(\"Degree\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Degree of best performing model on validation set: {degrees[np.argmin(val_loss)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By monitoring performance on both the training and validation sets, we can look for signs of **underfitting** and **overfitting**.\n",
    "\n",
    "In this example, we can avoid overfitting by choosing a suitable degree for our polynomial features such that the performance is optimised on the validation set. \n",
    "\n",
    "This technique is a form of **regularisation**, where we control the **model capacity** to avoid overfitting. There are several other regularisation techniques that we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Consider a dataset $(\\mathbf{x}_i, y_i)_{i=1}^N$, where each $y_i\\in\\{0, 1\\}$. Recall that the **logistic regression** model is given by \n",
    "\n",
    "$$\n",
    "f_\\theta(\\mathbf{x}) = \\sigma(\\theta^T\\phi(\\mathbf{x})),\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the sigmoid function, given by\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^-x}.\n",
    "$$\n",
    "\n",
    "The output of the function $f_\\theta$ is interpreted as the probability of the input $\\mathbf{x}$ belonging to the class label 1.\n",
    "\n",
    "We optimise the parameters by minimising the **binary cross entropy** loss function:\n",
    "\n",
    "$$\n",
    "L_{BCE}(\\theta) := -\\frac{1}{N}\\sum_{i=1}^N \\{y_i \\log f_\\theta(\\mathbf{x}_i) + (1 - y_i) \\log (1 - f_\\theta(\\mathbf{x}_i))\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"references\"></a>\n",
    "### References\n",
    "\n",
    "<a class=\"anchor\" id=\"Bishop06\"></a>\n",
    "* Bishop, C. M. (2006), \"Pattern Recognition and Machine Learning\", Springer-Verlag, Berlin, Heidelberg.\n",
    "<a class=\"anchor\" id=\"Hastie01\"></a>\n",
    "* Hastie, T., Tibshirani, R. & Friedman, J. (2001), \"The Elements of Statistical Learning\", Springer New York Inc., New York, NY, USA.\n",
    "<a class=\"anchor\" id=\"Mitchell97\"></a>\n",
    "* Mitchell, T. (1997), \"Machine Learning\", McGraw-Hill, New York.\n",
    "<a class=\"anchor\" id=\"Murphy12\"></a>\n",
    "* Murphy, K. P. (2012), \"Machine Learning: A Probabilistic Perspective\", The MIT Press.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
