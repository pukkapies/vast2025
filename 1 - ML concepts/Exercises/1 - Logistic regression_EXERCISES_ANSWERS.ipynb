{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf42181c-8e15-4d67-a0aa-1c1eff77027e",
   "metadata": {},
   "source": [
    "# Logistic regression exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7b225-56dd-402e-8ec9-767bb59b101b",
   "metadata": {},
   "source": [
    "We will use a toy dataset from `sklearn` to illustrate fitting a logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5b3d5-0114-4d4e-b12a-dfe308eeba61",
   "metadata": {},
   "source": [
    "**1. Create a toy dataset using the `make_blobs` function from `sklearn` (see [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html)). The dataset should have 150 samples from 2 clusters (centers), using a cluster standard deviation of 3.0. Save the input data points and labels into numpy arrays `X` and `y`, and print their shapes.**\n",
    "\n",
    "**Create a scatter plot of the dataset, colouring the points according to their cluster label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c6916-1011-482b-990f-76ac6a20395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(n_samples=150, centers=2, cluster_std=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0430b70-1c1d-4574-a7ac-291d5a466634",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e695404-8788-4104-a814-7c09e851e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='spring')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b26913-2fe5-43eb-96d8-f6420b7da7ef",
   "metadata": {},
   "source": [
    "**2. Create training and test splits with a 75/25 ratio. Make scatter plots showing the training and test splits separately, again colouring the points according to their label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55893a37-b54d-461d-b39d-6b4086cba4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60843bef-3bda-4bc1-813b-3ee6503ef883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 3))\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.scatter(Xtrain[:, 0], Xtrain[:, 1], c=ytrain, s=50, cmap='spring')\n",
    "\n",
    "ax2.set_title(\"Test set\")\n",
    "ax2.scatter(Xtest[:, 0], Xtest[:, 1], c=ytest, s=50, cmap='spring')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7b53f-428a-41f8-85b9-fc34210213bc",
   "metadata": {},
   "source": [
    "**3. Use the `LogisticRegression` class from `sklearn` (see [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), it is similar to the `LinearRegression` class) to train a logistic regression classifier on your toy dataset.**\n",
    "\n",
    "**Print the coefficients and intercept from your learned model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999b155-2970-4a2d-a5d3-06ece347712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "blobs_model = LogisticRegression()\n",
    "blobs_model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b8e6d-c2b0-48fd-bf31-e2211bf9f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_model.coef_, blobs_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f404dce-79df-445e-b622-3755ad587a17",
   "metadata": {},
   "source": [
    "**4. Display the training and test data points (separately), including the decision boundary from your logistic regression classifier. The decision boundary is defined as $\\{\\mathbf{x}: f_\\theta(\\mathbf{x}) = 0.5\\}$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca6e509-203c-4728-a4da-859f59d19665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = blobs_model.coef_[0]\n",
    "b = blobs_model.intercept_[0]\n",
    "\n",
    "x1 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x2 = (-b - w[0] * x1) / w[1]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10, 3))\n",
    "ax1.set_title(\"Training set\")\n",
    "ax1.scatter(Xtrain[:, 0], Xtrain[:, 1], c=ytrain, s=50, cmap='jet')\n",
    "ax1.plot(x1, x2, c='b', linewidth=3)\n",
    "\n",
    "ax2.set_title(\"Test set\")\n",
    "ax2.scatter(Xtest[:, 0], Xtest[:, 1], c=ytest, s=50, cmap='spring')\n",
    "ax2.plot(x1, x2, c='b', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14e107-3263-4a92-8da2-1c48e633d231",
   "metadata": {},
   "source": [
    "**5. Calculate the accuracy of your logistic regression classifier on the training and test datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277fa29b-8761-4e61-a26b-c53bddab4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train = blobs_model.predict(Xtrain)\n",
    "preds_test = blobs_model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8159258-8913-431d-8d00-2387c671621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train.shape, preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313491de-4b22-464b-8a13-2def79b594f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on training set: {(ytrain == preds_train).mean():.4f}\")\n",
    "print(f\"Accuracy on test set: {(ytest == preds_test).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd3b3ff-2aed-4d2a-b517-5ed3e5ac7abc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
